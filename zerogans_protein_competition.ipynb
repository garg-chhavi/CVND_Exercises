{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "zerogans-protein-competition.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garg-chhavi/CVND_Exercises/blob/master/zerogans_protein_competition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "YMzwBEDdEppk",
        "colab_type": "text"
      },
      "source": [
        "## Human Protein Multi Label Image Classification \n",
        "\n",
        "This is a starter notebook for the competition [Zero to GANs - Human Protein Classification](https://www.kaggle.com/c/jovian-pytorch-z2g)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "l45Wm3BuEppm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import make_grid\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": false,
        "id": "9kSN-WMgEpps",
        "colab_type": "text"
      },
      "source": [
        "## Exploring the Data\n",
        "\n",
        "When you create a notebook with the \"Notebooks\" tab of a Kaggle competition, the data is automatically included in the `../input` folder. You can explore the files in the sidebar. Let us create some constants acess the data directories and CSV files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "St8568GXEppt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = '../input/jovian-pytorch-z2g/Human protein atlas'\n",
        "\n",
        "TRAIN_DIR = DATA_DIR + '/train'                           # Contains training images\n",
        "TEST_DIR = DATA_DIR + '/test'                             # Contains test images\n",
        "\n",
        "TRAIN_CSV = DATA_DIR + '/train.csv'                       # Contains real labels for training images\n",
        "TEST_CSV = '../input/jovian-pytorch-z2g/submission.csv'   # Contains dummy labels for test image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArcEp-2hEppz",
        "colab_type": "text"
      },
      "source": [
        "The `train.csv` file contains image IDs and labels for training data. Note that this is a multi-label classification problem. Each image can have more than one type of protein."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "085Qi9uKEpp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head \"{TRAIN_CSV}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66VMXWCgEpp3",
        "colab_type": "text"
      },
      "source": [
        "Similarly, `submission.csv` contains image IDs for test data. However, since the goal of this competition is to make predictions for the test set, the `submission.csv` files contains **dummy labels**, which you need to replace with your predictions and sumbit to the competition on the \"Submission\" tab. In other words, we don't have the labels for the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eiOZlGKEEpp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head \"{TEST_CSV}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeC3MPwZEpp9",
        "colab_type": "text"
      },
      "source": [
        "The image files are named `<image-id>.png` and can be found in the respective `train` and `test` folders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "n0nMwSRMEpp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"{TRAIN_DIR}\" | head"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rarMmxE_EpqD",
        "colab_type": "text"
      },
      "source": [
        "Let's load the `train.csv` file into a Pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KhfgifajEpqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "h2368ziGEpqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_df.iloc[1,[1]]\n",
        "\n",
        "for l in str(train_df.iloc[1,[1]][0]).split(' '):\n",
        "    print(l)\n",
        "    \n",
        "train_df.iloc[1,[1]][0]\n",
        "str(train_df.iloc[1,[1]][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaOUsMDBEpqN",
        "colab_type": "text"
      },
      "source": [
        "Let's also put the textual labels in a dictionary for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8NBMn5RqEpqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = {\n",
        "    0: 'Mitochondria',\n",
        "    1: 'Nuclear bodies',\n",
        "    2: 'Nucleoli',\n",
        "    3: 'Golgi apparatus',\n",
        "    4: 'Nucleoplasm',\n",
        "    5: 'Nucleoli fibrillar center',\n",
        "    6: 'Cytosol',\n",
        "    7: 'Plasma membrane',\n",
        "    8: 'Centrosome',\n",
        "    9: 'Nuclear speckles'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqdu_ZR4EpqR",
        "colab_type": "text"
      },
      "source": [
        "To create a tensor from the labels, we will encode the labels as vectors of 1s & 0s. For example, if the labels are `'2 4 5'`, the correspoding vector for it would be `[0, 0, 1, 0, 1, 1, 0, 0, 0, 0]`. Let's define helper funtions to encode labels into tensors and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uhIsF9TaEpqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_label(label):\n",
        "    target = torch.zeros(10)\n",
        "    for l in str(label).split(' '):\n",
        "        target[int(l)] = 1.\n",
        "    return target\n",
        "\n",
        "def decode_target(target, text_labels=False, threshold=0.5):\n",
        "    result = []\n",
        "    for i, x in enumerate(target):\n",
        "        if (x >= threshold):\n",
        "            if text_labels:\n",
        "                result.append(labels[i] + \"(\" + str(i) + \")\")\n",
        "            else:\n",
        "                result.append(str(i))\n",
        "\n",
        "    return ' '.join(result)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7xCFPdvmEpqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_targets = []\n",
        "for row in range(train_df.shape[0]):\n",
        "    all_targets.append(encode_label(str(train_df.iloc[row,[1]][0])).tolist())\n",
        "all_targets = pd.DataFrame(all_targets, columns= labels.values())\n",
        "all_targets.apply(sum).plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fjMR6y8dEpqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encode_label('2 4 5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Fw79_QBbEpqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decode_target(torch.tensor([0, 0, 1, 0, 1, 1, 0, 0, 0, 0.]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PFkdaGYzEpqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decode_target(torch.tensor([0, 0, 1, 0, 1, 1, 0, 0, 0, 0.]), text_labels=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdgVjtv_Epql",
        "colab_type": "text"
      },
      "source": [
        "## Creating Datasets & Data Loaders\n",
        "\n",
        "We can now create a custom dataset by extending the `Dataset` class from PyTorch. We need to define the `__len__` and `__getitem__` methods to create a dataset. We'll also provide the option of adding transforms into the constructor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aWsqQsAyEpql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HumanProteinDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.root_dir = root_dir\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)    \n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.loc[idx]\n",
        "        img_id, img_label = row['Image'], row['Label']\n",
        "        img_fname = self.root_dir + \"/\" + str(img_id) + \".png\"\n",
        "        img = Image.open(img_fname)\n",
        "        #img = img1.filter(ImageFilter.BLUR)\n",
        "        #print(type(img))\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "            img = img\n",
        "        return img, encode_label(img_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0fyaulyEpqp",
        "colab_type": "text"
      },
      "source": [
        "Transforms can be chained using `transforms.Compose`. For instance, you may add `transforms.Resize(128)` before `transforms.ToTensor()` to resize images to size 128x128 before converting them into tensors. See the full list of transforms here: https://pytorch.org/docs/master/torchvision/transforms.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Tla964PEEpqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "j2gAK5FyEpqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.RandomCrop(400),\n",
        "                                transforms.RandomRotation((45,90)),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.RandomVerticalFlip(),\n",
        "                                transforms.ToTensor() ])\n",
        "dataset = HumanProteinDataset(TRAIN_CSV, TRAIN_DIR, transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-EFJtVO8Epqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset[0][0].min(), dataset[0][0].max(), dataset[0][0].mean(), dataset[0][0].std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DNnobPJ-Epq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalizing does not restrict limit between -1 and 1\n",
        "a = ((dataset[0][0] - 0.9416)/(.0898))\n",
        "a.min(), a.max(), a.mean(), a.std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxH5NCeCEpq2",
        "colab_type": "text"
      },
      "source": [
        "Let's check how many samples the dataset contains"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Th2iAyXuEpq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "s5n6g2dAEpq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset[0][1].shape, dataset[0][0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejvX13vIEpq8",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at a sample image from the dataset. We'll define a function `show_sample` to help us. We will also include the option to invert the image before showing it, because the original images are quite dark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MlyCWUKyEpq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_sample(img, target, invert=True):\n",
        "    if invert:\n",
        "        plt.imshow(1 - img.permute((1, 2, 0)))\n",
        "    else:\n",
        "        plt.imshow(img.permute(1, 2, 0))\n",
        "    print('Labels:', decode_target(target, text_labels=True))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs-2AKe1EprB",
        "colab_type": "text"
      },
      "source": [
        "Here's a sample image without the colors inverted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zCdwG8C1EprC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset[0][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SkNURymcEprF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_sample(dataset[2][0],dataset[2][1], invert=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKtANnoJEprI",
        "colab_type": "text"
      },
      "source": [
        "Here's the same image viewed with the colors inverted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NCBbn8xFEprJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_sample(*dataset[2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xNnQ-8SEprO",
        "colab_type": "text"
      },
      "source": [
        "### Training & Validation sets\n",
        "\n",
        "As a good practice, we should split the data into training and validation datasets. Let's fix a seed for PyTorch (to ensure we always get the same validation set), and create the datasets using `random_split`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PJuOPX-sEprP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82xq3iKEEprS",
        "colab_type": "text"
      },
      "source": [
        "I'm using a validation percentage of 10%, but you can use a smaller or larger percentage. One good strategy is to determine a good set of hyperparameters, and then retrain on a smaller validation set for your final submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lELqdqs3EprS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_pct = 0.1\n",
        "val_size = int(val_pct * len(dataset))\n",
        "train_size = len(dataset) - val_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hbfkRKkzEprV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "len(train_ds), len(val_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3NXUiO1EprY",
        "colab_type": "text"
      },
      "source": [
        "### Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4Mvj8h1_EprZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PPzq_VpoEprd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_dl = DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "C35uIPy6Eprg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_batch(dl, invert=True):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(16, 8))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        data = 1-images if invert else images\n",
        "        ax.imshow(make_grid(data, nrow=16).permute(1, 2, 0))\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JlFK8_aREpri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_batch(train_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C61ays5gEprm",
        "colab_type": "text"
      },
      "source": [
        "## View sample images with lables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_i2NfKz-Eprm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(train_dl)\n",
        "img = dataiter.next()\n",
        "images = img[0].numpy()\n",
        "\n",
        "labels_print = img[1]\n",
        "fig = plt.figure(figsize=(40, 40))\n",
        "for idx in np.arange(batch_size):\n",
        "    ax = fig.add_subplot(8, batch_size/8, idx+1, xticks=[], yticks=[])\n",
        "    a = 1 - (images[idx].transpose((1,2,0)))\n",
        "    ax.imshow(a)\n",
        "    ax.set_title(decode_target(labels_print[idx], text_labels=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zGoiBHi4Eprp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(train_dl)\n",
        "img = dataiter.next()\n",
        "images = img[0].numpy()\n",
        "\n",
        "labels_print = img[1]\n",
        "fig = plt.figure(figsize=(40, 40))\n",
        "for idx in np.arange(batch_size):\n",
        "    ax = fig.add_subplot(8, batch_size/8, idx+1, xticks=[], yticks=[])\n",
        "    a = (images[idx].transpose((1,2,0)))\n",
        "    ax.imshow(a)\n",
        "    ax.set_title(decode_target(labels_print[idx], text_labels=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ip23ASD0Eprt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show_batch(train_dl, invert = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9snqkTJEprx",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2LtBGpI1Eprx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def F_score(output, label, threshold=0.5, beta=1):\n",
        "    prob = output > threshold\n",
        "    label = label > threshold\n",
        "\n",
        "    TP = (prob & label).sum(1).float()\n",
        "    TN = ((~prob) & (~label)).sum(1).float()\n",
        "    FP = (prob & (~label)).sum(1).float()\n",
        "    FN = ((~prob) & label).sum(1).float()\n",
        "\n",
        "    precision = torch.mean(TP / (TP + FP + 1e-12))\n",
        "    recall = torch.mean(TP / (TP + FN + 1e-12))\n",
        "    F2 = (1 + beta**2) * precision * recall / (beta**2 * precision + recall + 1e-12)\n",
        "    return F2.mean(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1sQGg1k5Epr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultilabelImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, targets = batch \n",
        "        out = self(images)                      \n",
        "        loss = F.binary_cross_entropy(out, targets)      \n",
        "        return loss, out, targets\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, targets = batch \n",
        "        out = self(images)                           # Generate predictions\n",
        "        loss = F.binary_cross_entropy(out, targets)  # Calculate loss\n",
        "        score = F_score(out, targets)\n",
        "        return {'val_loss': loss.detach(), 'val_score': score.detach() }\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_scores = [x['val_score'] for x in outputs]\n",
        "        epoch_score = torch.stack(batch_scores).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_score': epoch_score.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, train_f_score: {:.4f}, val_loss: {:.4f}, val_score: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['train_f_score'], result['val_loss'], result['val_score']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "niMHdiSlEpr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ProteinCnnModel2(MultilabelImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use a pretrained model\n",
        "        self.network = models.resnet34(pretrained=True)\n",
        "        #self.network = models.vgg16(pretrained=True)\n",
        "        # Replace last layer\n",
        "        num_ftrs = self.network.fc.in_features\n",
        "        #for layers in self.network.parameters():\n",
        "         #   layers.requires_grad = False\n",
        "        \n",
        "        #for layers in (self.network.layer4[2].parameters()):\n",
        "        #    layers.requires_grad = True\n",
        "        \n",
        "        #self.network.fc = nn.Sequential(    \n",
        "         #                               nn.Linear(num_ftrs, 128),\n",
        "          #                              #nn.ReLU(),\n",
        "           #                             #nn.Dropout(0.5),\n",
        "            #                            #nn.Linear(256, 128),\n",
        "             #                           nn.ReLU(),\n",
        "              #                          nn.Dropout(0.4),\n",
        "               #                         nn.Linear(128, 10))\n",
        "        self.network.fc = nn.Linear(num_ftrs, 10)\n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fTSTdCwjEpr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ProteinCnnModel2()\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nTlS-EkSEpsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "suLwskojEpsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PEaM-L4rEpsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "to_device(model, device);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hm7zaQAPEpsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def try_batch(dl):\n",
        "    for images, labels in dl:\n",
        "        print('images.shape:', images.shape)\n",
        "        out = model(images)\n",
        "        print('out.shape:', out.shape)\n",
        "        print('out[0]:', out[0])\n",
        "        break\n",
        "\n",
        "try_batch(train_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iue68R9PEpsY",
        "colab_type": "text"
      },
      "source": [
        "If your kernel runs out of memory here, you might need to reduce your batch size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhZzFL3-EpsZ",
        "colab_type": "text"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "r14Va8xCEpsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-AHTAFZnEpsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD, best_validation_score = 1):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    #best_validation_score = 10\n",
        "    best_model = model\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        train_fscore = []\n",
        "        for batch in tqdm(train_loader):\n",
        "            loss, train_out, train_targets = model.training_step(batch)\n",
        "            batch_train_score = F_score(train_out, train_targets)\n",
        "            train_fscore.append(batch_train_score)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        \n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['train_f_score'] = torch.stack(train_fscore).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        \n",
        "        if(result['val_score'] > best_validation_score):\n",
        "            best_validation_score = result['val_score']\n",
        "            best_model = model\n",
        "            torch.save(model.state_dict(), 'resnet_1.pth')\n",
        "            \n",
        "        history.append(result)\n",
        "    return history, best_model, best_validation_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zr-_gQmAEpsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = to_device(ProteinCnnModel2(), device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "x4pxlsuCEpsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate(model, val_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SoWoIOgcEpsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#os.listdir(\"../input/dictionary\")\n",
        "#os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kYcxLcdjEpsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = torch.load(\"../input/dictionary/resnet_1.pth\")\n",
        "model.load_state_dict(checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LbssVs0bEpsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.network.parameters():\n",
        "    print(layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zh2iWOyDEpsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 10\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 1e-2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "w6zicAVIEps6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## %%time\n",
        "best_validation_score = 0.6238097548484802\n",
        "history, model, best_validation_score = fit(num_epochs, lr, model, train_dl, val_dl, opt_func, best_validation_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "biGMpaNcEps9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_validation_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zBGeoXrVEps_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "history, model, best_validation_score =  fit(5, lr, model, train_dl, val_dl, opt_func, best_validation_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "u5Omb-1oEptG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#torch.save(model.state_dict(), 'resnet_1.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1HRSN-qKEptI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "history, model, best_validation_score  = fit(5, .0001, model, train_dl, val_dl, opt_func, best_validation_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dueu_L06EptK",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zEP_ChXuEptK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yzjoRMdxEptV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9f9PG57oEptZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checkpoint = torch.load(PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dohdxsZqEptc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_score_list = [x['val_score'] for x in history]\n",
        "plt.plot(val_score_list)\n",
        "val_loss_list = [x['val_loss'] for x in history]\n",
        "plt.plot(val_loss_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_1RQachXEptf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#torch.save(history, 'resnet_1_history.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFDE1AClEptn",
        "colab_type": "text"
      },
      "source": [
        "## Making predictions & submission\n",
        "\n",
        "To start with, let's create a helper function to make a prediction on a single image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cQpxJRLjEpto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_single(image):\n",
        "    xb = image.unsqueeze(0)\n",
        "    xb = to_device(xb, device)\n",
        "    preds = model(xb)\n",
        "    prediction = preds[0]\n",
        "    print(\"Prediction: \", prediction)\n",
        "    show_sample(image, prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQc3-hPFEptq",
        "colab_type": "text"
      },
      "source": [
        "Next, let's create a test dataset using the `submission.csv` file. Note that the file contains dummy labels (always `'0'`). We'll use the same transforms we used for the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "raRZg260Eptr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = HumanProteinDataset(TEST_CSV, TEST_DIR, transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GodkGfkjEptt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img, target = test_dataset[0]\n",
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPLpp5msEptw",
        "colab_type": "text"
      },
      "source": [
        "Let's try predicting the labels for some sample images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DYEjrG2dEptw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_single(test_dataset[100][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oItIuDyYEpt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_single(test_dataset[74][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRgAC0pyEpt8",
        "colab_type": "text"
      },
      "source": [
        "## Creating a submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vWjYaT9DEpt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dl = DeviceDataLoader(DataLoader(test_dataset, batch_size, num_workers=2, pin_memory=True), device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_HXLE9uZEpuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@torch.no_grad()\n",
        "def predict_dl(dl, model):\n",
        "    torch.cuda.empty_cache()\n",
        "    batch_probs = []\n",
        "    for xb, _ in tqdm(dl):\n",
        "        probs = model(xb)\n",
        "        batch_probs.append(probs.cpu().detach())\n",
        "    batch_probs = torch.cat(batch_probs)\n",
        "    return [decode_target(x) for x in batch_probs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HoDzJrVEEpuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = predict_dl(test_dl, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ir9lUKakEpuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_validation_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C3onVadEpuP",
        "colab_type": "text"
      },
      "source": [
        "Let us know create a submission file with these predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1rkU97I9EpuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_df = pd.read_csv(TEST_CSV)\n",
        "submission_df.Label = test_preds\n",
        "submission_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9nWhHFjEpuT",
        "colab_type": "text"
      },
      "source": [
        "We can now save it batck to CSV, and download the file from the sidebar (check the output folder)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ShElScyiEpuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_fname = 'resnet34_submission_1.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sS2b0jUOEpub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_df.to_csv(sub_fname, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkDiSNAcEpue",
        "colab_type": "text"
      },
      "source": [
        "You can now upload this submission file here: https://www.kaggle.com/c/jovian-pytorch-z2g/submit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iF3My-yEpue",
        "colab_type": "text"
      },
      "source": [
        "## Save to Jovian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uiTPLNwGEpuf",
        "colab_type": "code",
        "colab": {},
        "outputId": "18a2e260-a090-4b0f-f253-158a6dfdc9f1"
      },
      "source": [
        "!pip install jovian --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jovian\n",
            "  Downloading jovian-0.2.15-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 1.8 MB/s eta 0:00:011\n",
            "\u001b[?25hCollecting uuid\n",
            "  Downloading uuid-1.30.tar.gz (5.8 kB)\n",
            "Requirement already satisfied, skipping upgrade: click in /opt/conda/lib/python3.7/site-packages (from jovian) (7.1.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.7/site-packages (from jovian) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/lib/python3.7/site-packages (from jovian) (5.3.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->jovian) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->jovian) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->jovian) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->jovian) (3.0.4)\n",
            "Building wheels for collected packages: uuid\n",
            "  Building wheel for uuid (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for uuid: filename=uuid-1.30-py3-none-any.whl size=6500 sha256=1e397a6c7ebe159968b26bfccbb987f539cb668ccb4b6969be57a149e655ea5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/ea/87/dd57f1ecb4f0752f3e1dbf958ebf8b36d920d190425bcdc24d\n",
            "Successfully built uuid\n",
            "Installing collected packages: uuid, jovian\n",
            "Successfully installed jovian-0.2.15 uuid-1.30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uYV4x5ZjEpuo",
        "colab_type": "code",
        "colab": {},
        "outputId": "775efa89-80a3-4e95-e80a-f822722de057"
      },
      "source": [
        "import jovian"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "K1u9760QEpur",
        "colab_type": "code",
        "colab": {},
        "outputId": "3bed24fc-0e4f-4259-a25c-c3e28b41504f"
      },
      "source": [
        "jovian.commit(project='zerogans-protein-competition')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n",
            "[jovian] Detected Kaggle notebook...\u001b[0m\n",
            "[jovian] Please enter your API key ( from https://jovian.ml/ ):\u001b[0m\n",
            "API KEY: ········\n",
            "[jovian] Uploading notebook to https://jovian.ml/garg-chhavi/zerogans-protein-competition\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    require([\"base/js/namespace\"],function(Jupyter) {\n",
              "        var nbJson = JSON.stringify(Jupyter.notebook.toJSON());\n",
              "\n",
              "        console.log(\"[jovian] Extracted notebook JSON:\");\n",
              "        console.log(nbJson);\n",
              "\n",
              "        function jvnLog (data) {\n",
              "          console.log(\"Result from jovian.commit:\");\n",
              "          if (data.content.text) {\n",
              "              var result = JSON.parse(data.content.text.trim());\n",
              "              var msg = result['msg'];\n",
              "              var err = result['err'];\n",
              "              if (msg) {\n",
              "                  element.text(\"Committed successfully: \" + msg)\n",
              "              } else {\n",
              "                  alert(\"Notebook commit failed. Error: \" + (err || \"Unknown\"))\n",
              "              }\n",
              "          }\n",
              "          \n",
              "        };\n",
              "        \n",
              "        var pythonCode = `\n",
              "from contextlib import redirect_stdout, redirect_stderr\n",
              "from io import StringIO\n",
              "import json\n",
              " \n",
              "with open(\"zerogans-protein-competition.ipynb\", 'w') as f:\n",
              "    f.write(r\"\"\"${nbJson}\"\"\")\n",
              "\n",
              "jvn_update = StringIO()\n",
              "jvn_update_err = StringIO()\n",
              "with redirect_stdout(jvn_update), redirect_stderr(jvn_update_err):\n",
              "    from jovian import commit\n",
              "\n",
              "jvn_f_out = StringIO()\n",
              "jvn_f_err = StringIO()\n",
              "with redirect_stdout(jvn_f_out), redirect_stderr(jvn_f_err):\n",
              "    jvn_msg = jovian.commit(project=\"zerogans-protein-competition\", filename=\"zerogans-protein-competition.ipynb\", environment=None)\n",
              "\n",
              "print(json.dumps({'msg': jvn_msg, 'err': jvn_f_err.getvalue(), 'update': jvn_update.getvalue()}))\n",
              "        `;\n",
              "\n",
              "        console.log(\"Invoking jovian.commit\")\n",
              "        // console.log(pythonCode)\n",
              "\n",
              "        Jupyter.notebook.kernel.execute(pythonCode, { iopub: { output: jvnLog }});\n",
              "    });"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HdQFP-wEput",
        "colab_type": "text"
      },
      "source": [
        "You can also use the \"Save Version\" button on Kaggle itself, to save a copy on your Kaggle profile."
      ]
    }
  ]
}